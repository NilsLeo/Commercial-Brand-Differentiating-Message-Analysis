{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting BDM In Superbowl Commercials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_md@ https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl#sha256=5e6329fe3fecedb1d1a02c3ea2172ee0fede6cea6e4aefb6a02d832dba78a310\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py==2.1.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: altair==5.5.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (5.5.0)\n",
      "Requirement already satisfied: annotated-types==0.7.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: appnope==0.1.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==3.0.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: attrs==24.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (24.3.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (4.12.3)\n",
      "Requirement already satisfied: bleach==6.2.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (6.2.0)\n",
      "Requirement already satisfied: blinker==1.9.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (1.9.0)\n",
      "Requirement already satisfied: blis==1.1.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (1.1.0)\n",
      "Requirement already satisfied: cachetools==5.5.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (5.5.0)\n",
      "Requirement already satisfied: catalogue==2.0.10 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 13)) (2.0.10)\n",
      "Requirement already satisfied: certifi==2024.12.14 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 14)) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 15)) (3.4.1)\n",
      "Requirement already satisfied: click==8.1.8 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 16)) (8.1.8)\n",
      "Requirement already satisfied: cloudpathlib==0.20.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 17)) (0.20.0)\n",
      "Requirement already satisfied: comm==0.2.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 18)) (0.2.2)\n",
      "Requirement already satisfied: confection==0.1.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 19)) (0.1.5)\n",
      "Requirement already satisfied: contourpy==1.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 20)) (1.3.0)\n",
      "Requirement already satisfied: cycler==0.12.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 21)) (0.12.1)\n",
      "Requirement already satisfied: cymem==2.0.10 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 22)) (2.0.10)\n",
      "Requirement already satisfied: debugpy==1.8.11 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 23)) (1.8.11)\n",
      "Requirement already satisfied: decorator==5.1.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 24)) (5.1.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 25)) (0.7.1)\n",
      "Requirement already satisfied: easyocr==1.7.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 26)) (1.7.2)\n",
      "Requirement already satisfied: et_xmlfile==2.0.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 29)) (2.0.0)\n",
      "Requirement already satisfied: exceptiongroup==1.2.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 30)) (1.2.2)\n",
      "Requirement already satisfied: executing==2.1.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 31)) (2.1.0)\n",
      "Requirement already satisfied: fastjsonschema==2.21.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 32)) (2.21.1)\n",
      "Requirement already satisfied: filelock==3.16.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 33)) (3.16.1)\n",
      "Requirement already satisfied: flatbuffers==24.12.23 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 34)) (24.12.23)\n",
      "Requirement already satisfied: fonttools==4.55.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 35)) (4.55.3)\n",
      "Requirement already satisfied: fsspec==2024.12.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 36)) (2024.12.0)\n",
      "Requirement already satisfied: gast==0.6.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 37)) (0.6.0)\n",
      "Requirement already satisfied: gitdb==4.0.12 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 38)) (4.0.12)\n",
      "Requirement already satisfied: GitPython==3.1.44 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 39)) (3.1.44)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 40)) (0.2.0)\n",
      "Requirement already satisfied: grpcio==1.68.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 41)) (1.68.1)\n",
      "Requirement already satisfied: h5py==3.12.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 42)) (3.12.1)\n",
      "Requirement already satisfied: huggingface-hub==0.27.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 43)) (0.27.0)\n",
      "Requirement already satisfied: idna==3.10 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 44)) (3.10)\n",
      "Requirement already satisfied: imageio==2.36.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 45)) (2.36.1)\n",
      "Requirement already satisfied: imbalanced-learn==0.12.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 46)) (0.12.4)\n",
      "Requirement already satisfied: imblearn==0.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 47)) (0.0)\n",
      "Requirement already satisfied: importlib_metadata==8.5.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 48)) (8.5.0)\n",
      "Requirement already satisfied: importlib_resources==6.4.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 49)) (6.4.5)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 50)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.18.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 51)) (8.18.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 52)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 53)) (3.1.5)\n",
      "Requirement already satisfied: joblib==1.4.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 54)) (1.4.2)\n",
      "Requirement already satisfied: jsonschema==4.23.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 55)) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications==2024.10.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 56)) (2024.10.1)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 57)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 58)) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 59)) (0.3.0)\n",
      "Requirement already satisfied: keras==3.7.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 60)) (3.7.0)\n",
      "Requirement already satisfied: kiwisolver==1.4.7 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 61)) (1.4.7)\n",
      "Requirement already satisfied: langcodes==3.5.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 62)) (3.5.0)\n",
      "Requirement already satisfied: language_data==1.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 63)) (1.3.0)\n",
      "Requirement already satisfied: lazy_loader==0.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 64)) (0.4)\n",
      "Requirement already satisfied: libclang==18.1.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 65)) (18.1.1)\n",
      "Requirement already satisfied: llvmlite==0.43.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 66)) (0.43.0)\n",
      "Requirement already satisfied: marisa-trie==1.2.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 67)) (1.2.1)\n",
      "Requirement already satisfied: Markdown==3.7 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 68)) (3.7)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 69)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 70)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib==3.9.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 71)) (3.9.4)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 72)) (0.1.7)\n",
      "Requirement already satisfied: mdurl==0.1.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 73)) (0.1.2)\n",
      "Requirement already satisfied: mistune==3.1.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 74)) (3.1.0)\n",
      "Requirement already satisfied: ml-dtypes==0.4.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 75)) (0.4.1)\n",
      "Requirement already satisfied: more-itertools==10.6.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 76)) (10.6.0)\n",
      "Requirement already satisfied: mpmath==1.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 77)) (1.3.0)\n",
      "Requirement already satisfied: murmurhash==1.0.11 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 78)) (1.0.11)\n",
      "Requirement already satisfied: namex==0.0.8 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 79)) (0.0.8)\n",
      "Requirement already satisfied: narwhals==1.20.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 80)) (1.20.1)\n",
      "Requirement already satisfied: nbclient==0.10.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 81)) (0.10.2)\n",
      "Requirement already satisfied: nbconvert==7.16.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 82)) (7.16.5)\n",
      "Requirement already satisfied: nbformat==5.10.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 83)) (5.10.4)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 84)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.2.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 85)) (3.2.1)\n",
      "Requirement already satisfied: ninja==1.11.1.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 86)) (1.11.1.3)\n",
      "Requirement already satisfied: nltk==3.9.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 87)) (3.9.1)\n",
      "Requirement already satisfied: numba==0.60.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 88)) (0.60.0)\n",
      "Requirement already satisfied: numpy==2.0.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 89)) (2.0.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 90)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 91)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 92)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 93)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 94)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 95)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 96)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 97)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 98)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 99)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 100)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 101)) (12.4.127)\n",
      "Requirement already satisfied: openai-whisper==20240930 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 102)) (20240930)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 103)) (4.11.0.86)\n",
      "Requirement already satisfied: opencv-python-headless==4.11.0.86 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 104)) (4.11.0.86)\n",
      "Requirement already satisfied: openpyxl==3.1.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 105)) (3.1.5)\n",
      "Requirement already satisfied: opt_einsum==3.4.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 106)) (3.4.0)\n",
      "Requirement already satisfied: optree==0.13.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 107)) (0.13.1)\n",
      "Requirement already satisfied: packaging==24.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 108)) (24.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 109)) (2.2.3)\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 110)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 111)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 112)) (4.9.0)\n",
      "Requirement already satisfied: pillow==11.1.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 113)) (11.1.0)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 114)) (4.3.6)\n",
      "Requirement already satisfied: preshed==3.0.9 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 115)) (3.0.9)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.48 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 116)) (3.0.48)\n",
      "Requirement already satisfied: protobuf==5.29.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 117)) (5.29.2)\n",
      "Requirement already satisfied: psutil==6.1.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 118)) (6.1.1)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 119)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 120)) (0.2.3)\n",
      "Requirement already satisfied: pyarrow==18.1.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 121)) (18.1.0)\n",
      "Requirement already satisfied: pyclipper==1.3.0.post6 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 122)) (1.3.0.post6)\n",
      "Requirement already satisfied: pydantic==2.10.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 123)) (2.10.4)\n",
      "Requirement already satisfied: pydantic_core==2.27.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 124)) (2.27.2)\n",
      "Requirement already satisfied: pydeck==0.9.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 125)) (0.9.1)\n",
      "Requirement already satisfied: pyenchant==3.2.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 126)) (3.2.2)\n",
      "Requirement already satisfied: Pygments==2.18.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 127)) (2.18.0)\n",
      "Requirement already satisfied: pyparsing==3.2.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 128)) (3.2.1)\n",
      "Requirement already satisfied: python-bidi==0.6.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 129)) (0.6.3)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 130)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 131)) (1.0.1)\n",
      "Requirement already satisfied: pytz==2024.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 132)) (2024.2)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 133)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.2.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 134)) (26.2.0)\n",
      "Requirement already satisfied: RapidFuzz==3.11.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 135)) (3.11.0)\n",
      "Requirement already satisfied: referencing==0.35.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 136)) (0.35.1)\n",
      "Requirement already satisfied: regex==2024.11.6 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 137)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 138)) (2.32.3)\n",
      "Requirement already satisfied: rich==13.9.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 139)) (13.9.4)\n",
      "Requirement already satisfied: rpds-py==0.22.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 140)) (0.22.3)\n",
      "Requirement already satisfied: safetensors==0.5.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 141)) (0.5.0)\n",
      "Requirement already satisfied: scikit-image==0.24.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 142)) (0.24.0)\n",
      "Requirement already satisfied: scikit-learn==1.6.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 143)) (1.6.0)\n",
      "Requirement already satisfied: scipy==1.13.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 144)) (1.13.1)\n",
      "Requirement already satisfied: seaborn==0.13.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 145)) (0.13.2)\n",
      "Requirement already satisfied: sentence-transformers==3.3.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 146)) (3.3.1)\n",
      "Requirement already satisfied: shapely==2.0.6 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 147)) (2.0.6)\n",
      "Requirement already satisfied: shellingham==1.5.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 148)) (1.5.4)\n",
      "Requirement already satisfied: six==1.17.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 149)) (1.17.0)\n",
      "Requirement already satisfied: smart-open==7.1.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 150)) (7.1.0)\n",
      "Requirement already satisfied: smmap==5.0.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 151)) (5.0.2)\n",
      "Requirement already satisfied: soupsieve==2.6 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 152)) (2.6)\n",
      "Requirement already satisfied: spacy==3.8.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 153)) (3.8.3)\n",
      "Requirement already satisfied: spacy-legacy==3.0.12 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 154)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers==1.0.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 155)) (1.0.5)\n",
      "Requirement already satisfied: srsly==2.5.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 156)) (2.5.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 157)) (0.6.3)\n",
      "Requirement already satisfied: streamlit==1.41.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 158)) (1.41.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 159)) (1.13.1)\n",
      "Requirement already satisfied: tabulate==0.9.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 160)) (0.9.0)\n",
      "Requirement already satisfied: tenacity==9.0.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 161)) (9.0.0)\n",
      "Requirement already satisfied: tensorboard==2.18.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 162)) (2.18.0)\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 163)) (0.7.2)\n",
      "Requirement already satisfied: tensorflow==2.18.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 164)) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-hub==0.16.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 165)) (0.16.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 166)) (0.37.1)\n",
      "Requirement already satisfied: termcolor==2.5.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 167)) (2.5.0)\n",
      "Requirement already satisfied: tf_keras==2.18.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 168)) (2.18.0)\n",
      "Requirement already satisfied: thinc==8.3.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 169)) (8.3.3)\n",
      "Requirement already satisfied: threadpoolctl==3.5.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 170)) (3.5.0)\n",
      "Requirement already satisfied: tifffile==2024.8.30 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 171)) (2024.8.30)\n",
      "Requirement already satisfied: tiktoken==0.8.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 172)) (0.8.0)\n",
      "Requirement already satisfied: tinycss2==1.4.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 173)) (1.4.0)\n",
      "Requirement already satisfied: tokenizers==0.21.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 174)) (0.21.0)\n",
      "Requirement already satisfied: toml==0.10.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 175)) (0.10.2)\n",
      "Requirement already satisfied: torch==2.5.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 176)) (2.5.1)\n",
      "Requirement already satisfied: torchvision==0.20.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 177)) (0.20.1)\n",
      "Requirement already satisfied: tornado==6.4.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 178)) (6.4.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 179)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 180)) (5.14.3)\n",
      "Requirement already satisfied: transformers==4.47.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 181)) (4.47.1)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 182)) (3.1.0)\n",
      "Requirement already satisfied: typer==0.15.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 183)) (0.15.1)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 184)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2024.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 185)) (2024.2)\n",
      "Requirement already satisfied: urllib3==2.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 186)) (2.3.0)\n",
      "Requirement already satisfied: wasabi==1.1.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 187)) (1.1.3)\n",
      "Requirement already satisfied: watchdog==6.0.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 188)) (6.0.0)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 189)) (0.2.13)\n",
      "Requirement already satisfied: weasel==0.4.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 190)) (0.4.1)\n",
      "Requirement already satisfied: webencodings==0.5.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 191)) (0.5.1)\n",
      "Requirement already satisfied: Werkzeug==3.1.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 192)) (3.1.3)\n",
      "Requirement already satisfied: whisper==1.1.10 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 193)) (1.1.10)\n",
      "Requirement already satisfied: wrapt==1.17.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 194)) (1.17.0)\n",
      "Requirement already satisfied: zipp==3.21.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 195)) (3.21.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.9/site-packages (from astunparse==1.6.3->-r requirements.txt (line 6)) (0.45.1)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (from marisa-trie==1.2.1->-r requirements.txt (line 67)) (58.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/home/arkastor/Development/Commercial-Brand-Differentiating-Message-Analysis/app/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='log.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have some specific knowledge about the industry and brand, so we can use that to improve the model. This data only exists for a few brands and products. Activate or deactivate as needed.\n",
    "INDUSTRY_SPECIFIC_AWARENESS = True\n",
    "BRAND_SPECIFIC_AWARENESS = True\n",
    "\n",
    "# Activate if you want to reduce the selection of commercials to 20 for debugging\n",
    "REDUCED_SELECTION = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints\n",
    "# Since the model takes very long to train, we save extracted features to csvs and only rerun the code if the csv \"checkpoint\" does not exist\n",
    "\n",
    "BASELINE_CHECKPOINT = os.path.exists('csvs/baseline.csv')\n",
    "logging.info(f\"Baseline checkpoint: {BASELINE_CHECKPOINT}\")\n",
    "TRANSCRIPT_CHECKPOINT = os.path.exists('csvs/transcript.csv')\n",
    "logging.info(f\"Transcript checkpoint: {TRANSCRIPT_CHECKPOINT}\")\n",
    "OCR_CHECKPOINT = os.path.exists('csvs/ocr.csv')\n",
    "logging.info(f\"OCR checkpoint: {OCR_CHECKPOINT}\")\n",
    "BDM_WORDS_CHECKPOINT = os.path.exists('csvs/bdm_words.csv')\n",
    "logging.info(f\"BDM words checkpoint: {BDM_WORDS_CHECKPOINT}\")\n",
    "ADJ_NOUN_PAIRS_CHECKPOINT = os.path.exists('csvs/adj_noun_pairs.csv')\n",
    "logging.info(f\"Adj noun pairs checkpoint: {ADJ_NOUN_PAIRS_CHECKPOINT}\")\n",
    "SEMANTIC_SIMILARITY_CHECKPOINT = os.path.exists('csvs/semantic_similarity.csv')\n",
    "logging.info(f\"Semantic similarity checkpoint: {SEMANTIC_SIMILARITY_CHECKPOINT}\")\n",
    "PERSONAL_PRONOUNS_CHECKPOINT = os.path.exists('csvs/personal_pronouns.csv')\n",
    "logging.info(f\"Personal pronouns checkpoint: {PERSONAL_PRONOUNS_CHECKPOINT}\")\n",
    "# Activate if you want to completely rerun the notebook from scratch. This will delete all csvs/ saved data and start from scratch.\n",
    "RESTART_FROM_SCRATCH = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "csv_dir = \"./csvs\"\n",
    "if RESTART_FROM_SCRATCH and os.path.exists(csv_dir):\n",
    "    shutil.rmtree(csv_dir)\n",
    "    logging.info(f\"Directory '{csv_dir}' has been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRISP-DM 3: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_videos():\n",
    "  url = 'https://box.fu-berlin.de/s/zwxKp8PXkCwAwGe/download'\n",
    "  download_filename = 'downloaded_archive.zip'\n",
    "  target_directory = 'ADs'\n",
    "  os.system(f'wget -O {download_filename} {url}')\n",
    "  os.makedirs(target_directory, exist_ok=True)\n",
    "  os.system(f'unzip -o {download_filename} -d {target_directory}')\n",
    "  os.remove(download_filename)\n",
    "  logging.info(f\"Archive extracted to {target_directory} and {download_filename} removed.\")\n",
    "\n",
    "if not BASELINE_CHECKPOINT:\n",
    "  pass\n",
    "  # download_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25932/2614883329.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ad_df.rename(columns={'cont_primary_product_type': 'product_category', 'BRAND': 'brand', 'AdNumber': 'commercial_number', 'cont_com_appeal': 'commercial_appeal', 'cont_csr_type': 'csr_type', 'Emotion_from_Dialogue': 'emotion_from_dialogue'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category</th>\n",
       "      <th>brand</th>\n",
       "      <th>commercial_number</th>\n",
       "      <th>commercial_appeal</th>\n",
       "      <th>csr_type</th>\n",
       "      <th>emotion_from_dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Audi</td>\n",
       "      <td>AD0252</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Axe</td>\n",
       "      <td>AD0253</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>BestBuy</td>\n",
       "      <td>AD0254</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>BlackBerry</td>\n",
       "      <td>AD0255</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Beck's Beer</td>\n",
       "      <td>AD0256</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Budweiser</td>\n",
       "      <td>AD0257</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Budweiser</td>\n",
       "      <td>AD0258</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Bud Light</td>\n",
       "      <td>AD0259</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Budweiser</td>\n",
       "      <td>AD0260</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>CalvinKlein</td>\n",
       "      <td>AD0261</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_category        brand commercial_number  commercial_appeal  \\\n",
       "0               4.0         Audi            AD0252                3.0   \n",
       "1               8.0          Axe            AD0253                3.0   \n",
       "2              19.0      BestBuy            AD0254                2.0   \n",
       "3               7.0   BlackBerry            AD0255                3.0   \n",
       "4               2.0  Beck's Beer            AD0256                3.0   \n",
       "5               2.0    Budweiser            AD0257                3.0   \n",
       "6               2.0    Budweiser            AD0258                3.0   \n",
       "7               2.0    Bud Light            AD0259                3.0   \n",
       "8               2.0    Budweiser            AD0260                3.0   \n",
       "9              10.0  CalvinKlein            AD0261                3.0   \n",
       "\n",
       "   csr_type emotion_from_dialogue  \n",
       "0       0.0                   NaN  \n",
       "1       0.0                   joy  \n",
       "2       0.0                   NaN  \n",
       "3       0.0                   NaN  \n",
       "4       0.0                   NaN  \n",
       "5       0.0                   NaN  \n",
       "6       0.0                   NaN  \n",
       "7       0.0                   NaN  \n",
       "8       0.0                   NaN  \n",
       "9       0.0                   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25932/2614883329.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ad_df['encoded_emotion'] = emotion_columns.apply(lambda x: 1 if x in target_emotions else 0)\n"
     ]
    }
   ],
   "source": [
    "if not BASELINE_CHECKPOINT:\n",
    "\n",
    "\n",
    "    BDM_excel = pd.read_excel('BDM.xlsx')\n",
    "    final_excel = pd.read_excel('previous_project_results.xlsx')\n",
    "    final_excel = final_excel.merge(\n",
    "    BDM_excel[['AdNumber', 'BDM']], \n",
    "    on='AdNumber', \n",
    "    how='left',\n",
    "    suffixes=('_old', '')\n",
    "    ).drop('BDM_old', axis=1, errors='ignore')\n",
    "    ad_df = final_excel\n",
    "    ad_df = ad_df[['cont_primary_product_type', 'BRAND', 'AdNumber', 'cont_com_appeal', 'cont_csr_type', 'Emotion_from_Dialogue']]\n",
    "    ad_df.rename(columns={'cont_primary_product_type': 'product_category', 'BRAND': 'brand', 'AdNumber': 'commercial_number', 'cont_com_appeal': 'commercial_appeal', 'cont_csr_type': 'csr_type', 'Emotion_from_Dialogue': 'emotion_from_dialogue'}, inplace=True)\n",
    "    ad_df.head(10)\n",
    "    display(ad_df.head(10))\n",
    "    # Manual coding by the marketing team: 1 = rational, 2 = balanced, 3 = emotional\n",
    "    sentiment_columns = ad_df[\"commercial_appeal\"]\n",
    "\n",
    "    # Sentiment analysis from the last project group for audio transcription\n",
    "    # Encoding 0: p < 0.8 = neutral\n",
    "    # Encoding 1: p > 0.8 = emotional\n",
    "\n",
    "    emotion_columns = ad_df[\"emotion_from_dialogue\"]\n",
    "\n",
    "    # List of values to be encoded as 1\n",
    "    target_emotions = ['love', 'joy', 'surprise', 'sadness', 'anger', 'fear']\n",
    "    ad_df['encoded_emotion'] = emotion_columns.apply(lambda x: 1 if x in target_emotions else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brand Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25932/3845249353.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ad_df['brand_clean'] = ad_df['brand'].str.replace(' ', '').str.lower()\n"
     ]
    }
   ],
   "source": [
    "if not BASELINE_CHECKPOINT:\n",
    "    if BRAND_SPECIFIC_AWARENESS:\n",
    "        product_brand_df = pd.read_csv(\"product_brands.csv\")\n",
    "\n",
    "        product_brand_df['brand'] = product_brand_df['brand'].str.replace(' ', '').str.lower()\n",
    "        ad_df['brand_clean'] = ad_df['brand'].str.replace(' ', '').str.lower()\n",
    "\n",
    "        ad_df = ad_df.merge(\n",
    "            product_brand_df[['brand', 'product_brand_keywords']], \n",
    "            left_on='brand_clean',\n",
    "            right_on='brand',\n",
    "            how='left',\n",
    "            suffixes=('', '_brand')\n",
    "        )\n",
    "\n",
    "        ad_df.drop(['brand_clean', 'brand_brand'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Category Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_cat_name</th>\n",
       "      <th>product_cat_keywords</th>\n",
       "      <th>product_cat_brands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alcoholic beverages (Beer Hard Seltzer)</td>\n",
       "      <td>['smooth', 'rich', 'refreshing', 'aromatic', '...</td>\n",
       "      <td>['Anheuser Busch InBev', 'Becks Beer', 'Bud Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Banking &amp; Investments</td>\n",
       "      <td>['secure', 'reliable', 'customized', 'personal...</td>\n",
       "      <td>['BankofAmerica', 'Coinbase', 'Cryptocom', 'Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Car Accessories &amp; Related Services</td>\n",
       "      <td>['safe', 'protect', 'protected', 'protection',...</td>\n",
       "      <td>['Michelin', 'Wallbox', 'Weathertech']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Car Manufacturer</td>\n",
       "      <td>['Luxurious', 'Efficient', 'Powerful', 'Innova...</td>\n",
       "      <td>['Acura', 'AlfaRomeo', 'Audi', 'BMW', 'Buick',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Car Sales &amp; Services Platform</td>\n",
       "      <td>['easy', 'perfect', 'love', 'expert', 'really'...</td>\n",
       "      <td>['Carvana', 'Vroom', 'Carscom', 'Carmax']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clothing, shoes and apparel</td>\n",
       "      <td>['favorite', 'designed', 'comfortable', 'uncom...</td>\n",
       "      <td>['CalvinKlein', 'Gildan', 'HANDM', 'Marmot', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Consumer Electronics and Appliances</td>\n",
       "      <td>['Smart', 'Display', 'Control', 'Touchscreen',...</td>\n",
       "      <td>['BlackBerry', 'Google', 'Intel', 'LGEEAudioVi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cosmetics and personal care products</td>\n",
       "      <td>['luxurious', 'nourishing', 'radiant', 'smooth...</td>\n",
       "      <td>['Fitbit', 'PlanetFitness']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Diet and exercise products</td>\n",
       "      <td>['healthy', 'energizing', 'effective', 'smart'...</td>\n",
       "      <td>['CalvinKlein', 'Gildan', 'Marmot', 'Skechers'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Food Delivery Services</td>\n",
       "      <td>['easy', 'delivered', 'local', 'convenience', ...</td>\n",
       "      <td>['DoorDash', 'UberEats']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Games</td>\n",
       "      <td>['Free', 'Exclusive', 'Unlimited', 'Anywhere',...</td>\n",
       "      <td>['MachineZone', 'MobileStrike', 'Pokemon', 'Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>General Retailers</td>\n",
       "      <td>['VIP', 'scan', 'go', 'breathe', 'line', 'stun...</td>\n",
       "      <td>['SamsClub', 'Walmart', '84Lumber']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Healthcare and Medical Products</td>\n",
       "      <td>['reliable', 'effective', 'innovative', 'advan...</td>\n",
       "      <td>['CueHealth', 'Dexcom', 'Hologic', 'Advil', 'A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Household and lawn and garden supplies</td>\n",
       "      <td>['powerful', 'effective', 'reliable', 'fast-ac...</td>\n",
       "      <td>['Febreze', 'Loctite', 'MrClean', 'PersilProCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Insurance</td>\n",
       "      <td>['reliable', 'affordable', 'comprehensive', 's...</td>\n",
       "      <td>['AmericanFamilyInsurance', 'Esurance', 'Geico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Web Services and Digital Solutions</td>\n",
       "      <td>['innovative', 'reliable', 'secure', 'intuitiv...</td>\n",
       "      <td>['GoDaddy', 'Google', 'Salesforce', 'Squarespa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nonprofit organizations</td>\n",
       "      <td>['dedicated', 'compassionate', 'impactful', 'm...</td>\n",
       "      <td>['AmericanPetroleumInstitute', 'DonaldTrumpCam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Quick Service Restaurants &amp; Food Chains</td>\n",
       "      <td>['fresh', 'enjoy', 'organic', 'natural', 'deli...</td>\n",
       "      <td>['BurgerKing', 'Chipotle', 'HardRock', 'JimmyJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Smart Home Devices</td>\n",
       "      <td>['Safe', 'Trusted', 'Reliable', 'Efficient', '...</td>\n",
       "      <td>['ADT', 'Amazon', 'AmazonAlexa', 'AmazonEcho',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>['artificial', 'zero', 'refreshing', 'organic'...</td>\n",
       "      <td>['Butterfinger', 'Cheerios', 'Cheetos', 'Choba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Social Media</td>\n",
       "      <td>['first', 'move', 'power', 'stand out', 'rock'...</td>\n",
       "      <td>['BLACTURE', 'Bumble', 'Facebook']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Softdrinks</td>\n",
       "      <td>['refreshing', 'organic', 'fizzy', 'sparkling'...</td>\n",
       "      <td>['Bai', 'BUBLY', 'CocaCola', 'DietCoke', 'MiO'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Non-Softdrinks (Water, Milk, Milk Substitutes)</td>\n",
       "      <td>['pure', 'refreshing', 'natural', 'nature', 's...</td>\n",
       "      <td>['Fiji', 'LifeWTR', 'Oatly', 'GotMilk']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Streaming Service</td>\n",
       "      <td>['innovative', 'seamless', 'immersive', 'exclu...</td>\n",
       "      <td>['AmazonPrimeVideo', 'DisneyPlus', 'Hulu', 'Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Telecommuniactions services</td>\n",
       "      <td>['5G', 'LTE', 'network', 'sound', 'unlimited',...</td>\n",
       "      <td>['Mint', 'Sprint', 'TMobile', 'VerizonWireless']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Television and Radio</td>\n",
       "      <td>['entertaining', 'dynamic', 'exclusive', 'inno...</td>\n",
       "      <td>['AMC', 'NBC', 'NFL']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Travel and Booking Platforms</td>\n",
       "      <td>['Discover', 'Widen', 'Feel', 'Connect', 'Go',...</td>\n",
       "      <td>['Airbnb', 'Apartmentscom', 'TOURISMAUSTRALIA'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  product_cat_name  \\\n",
       "0          Alcoholic beverages (Beer Hard Seltzer)   \n",
       "1                            Banking & Investments   \n",
       "2               Car Accessories & Related Services   \n",
       "3                                 Car Manufacturer   \n",
       "4                    Car Sales & Services Platform   \n",
       "5                      Clothing, shoes and apparel   \n",
       "6              Consumer Electronics and Appliances   \n",
       "7             Cosmetics and personal care products   \n",
       "8                       Diet and exercise products   \n",
       "9                           Food Delivery Services   \n",
       "10                                           Games   \n",
       "11                               General Retailers   \n",
       "12                 Healthcare and Medical Products   \n",
       "13          Household and lawn and garden supplies   \n",
       "14                                       Insurance   \n",
       "15              Web Services and Digital Solutions   \n",
       "16                         Nonprofit organizations   \n",
       "17         Quick Service Restaurants & Food Chains   \n",
       "18                              Smart Home Devices   \n",
       "19                                          Snacks   \n",
       "20                                    Social Media   \n",
       "21                                      Softdrinks   \n",
       "22  Non-Softdrinks (Water, Milk, Milk Substitutes)   \n",
       "23                              Streaming Service    \n",
       "24                     Telecommuniactions services   \n",
       "25                            Television and Radio   \n",
       "26                    Travel and Booking Platforms   \n",
       "\n",
       "                                 product_cat_keywords  \\\n",
       "0   ['smooth', 'rich', 'refreshing', 'aromatic', '...   \n",
       "1   ['secure', 'reliable', 'customized', 'personal...   \n",
       "2   ['safe', 'protect', 'protected', 'protection',...   \n",
       "3   ['Luxurious', 'Efficient', 'Powerful', 'Innova...   \n",
       "4   ['easy', 'perfect', 'love', 'expert', 'really'...   \n",
       "5   ['favorite', 'designed', 'comfortable', 'uncom...   \n",
       "6   ['Smart', 'Display', 'Control', 'Touchscreen',...   \n",
       "7   ['luxurious', 'nourishing', 'radiant', 'smooth...   \n",
       "8   ['healthy', 'energizing', 'effective', 'smart'...   \n",
       "9   ['easy', 'delivered', 'local', 'convenience', ...   \n",
       "10  ['Free', 'Exclusive', 'Unlimited', 'Anywhere',...   \n",
       "11  ['VIP', 'scan', 'go', 'breathe', 'line', 'stun...   \n",
       "12  ['reliable', 'effective', 'innovative', 'advan...   \n",
       "13  ['powerful', 'effective', 'reliable', 'fast-ac...   \n",
       "14  ['reliable', 'affordable', 'comprehensive', 's...   \n",
       "15  ['innovative', 'reliable', 'secure', 'intuitiv...   \n",
       "16  ['dedicated', 'compassionate', 'impactful', 'm...   \n",
       "17  ['fresh', 'enjoy', 'organic', 'natural', 'deli...   \n",
       "18  ['Safe', 'Trusted', 'Reliable', 'Efficient', '...   \n",
       "19  ['artificial', 'zero', 'refreshing', 'organic'...   \n",
       "20  ['first', 'move', 'power', 'stand out', 'rock'...   \n",
       "21  ['refreshing', 'organic', 'fizzy', 'sparkling'...   \n",
       "22  ['pure', 'refreshing', 'natural', 'nature', 's...   \n",
       "23  ['innovative', 'seamless', 'immersive', 'exclu...   \n",
       "24  ['5G', 'LTE', 'network', 'sound', 'unlimited',...   \n",
       "25  ['entertaining', 'dynamic', 'exclusive', 'inno...   \n",
       "26  ['Discover', 'Widen', 'Feel', 'Connect', 'Go',...   \n",
       "\n",
       "                                   product_cat_brands  \n",
       "0   ['Anheuser Busch InBev', 'Becks Beer', 'Bud Li...  \n",
       "1   ['BankofAmerica', 'Coinbase', 'Cryptocom', 'Di...  \n",
       "2              ['Michelin', 'Wallbox', 'Weathertech']  \n",
       "3   ['Acura', 'AlfaRomeo', 'Audi', 'BMW', 'Buick',...  \n",
       "4           ['Carvana', 'Vroom', 'Carscom', 'Carmax']  \n",
       "5   ['CalvinKlein', 'Gildan', 'HANDM', 'Marmot', '...  \n",
       "6   ['BlackBerry', 'Google', 'Intel', 'LGEEAudioVi...  \n",
       "7                         ['Fitbit', 'PlanetFitness']  \n",
       "8   ['CalvinKlein', 'Gildan', 'Marmot', 'Skechers'...  \n",
       "9                            ['DoorDash', 'UberEats']  \n",
       "10  ['MachineZone', 'MobileStrike', 'Pokemon', 'Su...  \n",
       "11                ['SamsClub', 'Walmart', '84Lumber']  \n",
       "12  ['CueHealth', 'Dexcom', 'Hologic', 'Advil', 'A...  \n",
       "13  ['Febreze', 'Loctite', 'MrClean', 'PersilProCl...  \n",
       "14  ['AmericanFamilyInsurance', 'Esurance', 'Geico...  \n",
       "15  ['GoDaddy', 'Google', 'Salesforce', 'Squarespa...  \n",
       "16  ['AmericanPetroleumInstitute', 'DonaldTrumpCam...  \n",
       "17  ['BurgerKing', 'Chipotle', 'HardRock', 'JimmyJ...  \n",
       "18  ['ADT', 'Amazon', 'AmazonAlexa', 'AmazonEcho',...  \n",
       "19  ['Butterfinger', 'Cheerios', 'Cheetos', 'Choba...  \n",
       "20                 ['BLACTURE', 'Bumble', 'Facebook']  \n",
       "21  ['Bai', 'BUBLY', 'CocaCola', 'DietCoke', 'MiO'...  \n",
       "22            ['Fiji', 'LifeWTR', 'Oatly', 'GotMilk']  \n",
       "23  ['AmazonPrimeVideo', 'DisneyPlus', 'Hulu', 'Pa...  \n",
       "24   ['Mint', 'Sprint', 'TMobile', 'VerizonWireless']  \n",
       "25                              ['AMC', 'NBC', 'NFL']  \n",
       "26  ['Airbnb', 'Apartmentscom', 'TOURISMAUSTRALIA'...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>commercial_number</th>\n",
       "      <th>commercial_appeal</th>\n",
       "      <th>csr_type</th>\n",
       "      <th>emotion_from_dialogue</th>\n",
       "      <th>encoded_emotion</th>\n",
       "      <th>product_brand_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Audi</td>\n",
       "      <td>AD0252</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>sustainable', 'future', 'electric', 'all-elect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Axe</td>\n",
       "      <td>AD0253</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>joy</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BestBuy</td>\n",
       "      <td>AD0254</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BlackBerry</td>\n",
       "      <td>AD0255</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beck's Beer</td>\n",
       "      <td>AD0256</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           brand commercial_number  commercial_appeal  csr_type  \\\n",
       "0           Audi            AD0252                3.0       0.0   \n",
       "1            Axe            AD0253                3.0       0.0   \n",
       "2        BestBuy            AD0254                2.0       0.0   \n",
       "3     BlackBerry            AD0255                3.0       0.0   \n",
       "4    Beck's Beer            AD0256                3.0       0.0   \n",
       "..           ...               ...                ...       ...   \n",
       "567          NaN               NaN                NaN       NaN   \n",
       "568          NaN               NaN                NaN       NaN   \n",
       "569          NaN               NaN                NaN       NaN   \n",
       "570          NaN               NaN                NaN       NaN   \n",
       "571          NaN               NaN                NaN       NaN   \n",
       "\n",
       "    emotion_from_dialogue  encoded_emotion  \\\n",
       "0                     NaN                0   \n",
       "1                     joy                1   \n",
       "2                     NaN                0   \n",
       "3                     NaN                0   \n",
       "4                     NaN                0   \n",
       "..                    ...              ...   \n",
       "567                   NaN                0   \n",
       "568                   NaN                0   \n",
       "569                   NaN                0   \n",
       "570                   NaN                0   \n",
       "571                   NaN                0   \n",
       "\n",
       "                                product_brand_keywords  \n",
       "0    sustainable', 'future', 'electric', 'all-elect...  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "567                                                NaN  \n",
       "568                                                NaN  \n",
       "569                                                NaN  \n",
       "570                                                NaN  \n",
       "571                                                NaN  \n",
       "\n",
       "[572 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m brand_to_info\u001b[38;5;241m.\u001b[39mget(clean_brand)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m product_brands_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m---> 21\u001b[0m     ad_df[col] \u001b[38;5;241m=\u001b[39m \u001b[43mad_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbrand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfind_brand_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfind_brand_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m unmapped_brands \u001b[38;5;241m=\u001b[39m ad_df[ad_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_cat_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrand\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unmapped_brands) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/app/.venv/lib/python3.9/site-packages/pandas/core/series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/app/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/app/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/app/.venv/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/app/.venv/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m brand_to_info\u001b[38;5;241m.\u001b[39mget(clean_brand)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m product_brands_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m---> 21\u001b[0m     ad_df[col] \u001b[38;5;241m=\u001b[39m ad_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrand\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: find_brand_info(x)[col] \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfind_brand_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m unmapped_brands \u001b[38;5;241m=\u001b[39m ad_df[ad_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_cat_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrand\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unmapped_brands) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m, in \u001b[0;36mfind_brand_info\u001b[0;34m(brand)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_brand_info\u001b[39m(brand):\n\u001b[0;32m---> 17\u001b[0m     clean_brand \u001b[38;5;241m=\u001b[39m \u001b[43mbrand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m brand_to_info\u001b[38;5;241m.\u001b[39mget(clean_brand)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "if not BASELINE_CHECKPOINT:\n",
    "    if INDUSTRY_SPECIFIC_AWARENESS:\n",
    "        product_brands_df = pd.read_csv(\"product_categories.csv\")\n",
    "        product_brands_df.head(40)\n",
    "        product_brands_df = product_brands_df.drop('product_cat_id', axis=1)\n",
    "        ad_df = ad_df.drop('product_category', axis=1)\n",
    "        display(product_brands_df)\n",
    "        display(ad_df)\n",
    "        brand_to_info = {}\n",
    "        for _, row in product_brands_df.iterrows():\n",
    "            brands = eval(row['product_cat_brands'])\n",
    "            for brand in brands:\n",
    "                brand = brand.replace(' ', '').lower()\n",
    "                brand_to_info[brand] = {col: row[col] for col in product_brands_df.columns}\n",
    "\n",
    "        def find_brand_info(brand):\n",
    "            clean_brand = brand.replace(' ', '').lower()\n",
    "            return brand_to_info.get(clean_brand)\n",
    "\n",
    "        for col in product_brands_df.columns:\n",
    "            ad_df[col] = ad_df['brand'].apply(lambda x: find_brand_info(x)[col] if find_brand_info(x) else None)\n",
    "\n",
    "        unmapped_brands = ad_df[ad_df['product_cat_name'].isna()]['brand'].unique()\n",
    "        if len(unmapped_brands) > 0:\n",
    "            logging.info(\"Brands without category mapping:\")\n",
    "            for brand in unmapped_brands:\n",
    "                logging.info(f\"- {brand}\")\n",
    "\n",
    "        ad_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not BASELINE_CHECKPOINT:\n",
    "  if REDUCED_SELECTION:\n",
    "    ad_df = ad_df.head(20)\n",
    "  directory = 'csvs'\n",
    "  if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "  ad_df.to_csv('csvs/baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature: Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_df = pd.read_csv('csvs/baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "from transcript import transcribe_video\n",
    "from ocr import ocr\n",
    "\n",
    "if not TRANSCRIPT_CHECKPOINT:\n",
    "    ads_dir = \"ADs\"\n",
    "    def find_video_file(commercial_number, ads_dir):\n",
    "        \"\"\"Find the video file path for a given commercial number.\"\"\"\n",
    "        # Search recursively for MP4 files\n",
    "        pattern = f\"{ads_dir}/**/{commercial_number}.mp4\"\n",
    "        matches = glob.glob(pattern, recursive=True)\n",
    "        return matches[0] if matches else None\n",
    "\n",
    "    ad_df['transcript'] = ''\n",
    "\n",
    "    for idx, row in ad_df.iterrows():\n",
    "        commercial_number = row['commercial_number']\n",
    "        video_path = find_video_file(commercial_number, ads_dir)\n",
    "        \n",
    "        if video_path:\n",
    "            transcript = transcribe_video(video_path)\n",
    "            ad_df.at[idx, 'transcript'] = transcript\n",
    "        else:\n",
    "            logging.info(f\"Video not found for commercial {commercial_number}\")\n",
    "    ad_df[['commercial_number', 'transcript']].to_csv('csvs/transcript.csv', index=False)\n",
    "    ad_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature: OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transcript_df = pd.read_csv('csvs/transcript.csv')\n",
    "ad_df = ad_df.merge(transcript_df, on='commercial_number', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "from transcript import transcribe_video\n",
    "from ocr import ocr\n",
    "\n",
    "if not OCR_CHECKPOINT:\n",
    "    ads_dir = \"ADs\"\n",
    "    def find_video_file(commercial_number, ads_dir):\n",
    "        \"\"\"Find the video file path for a given commercial number.\"\"\"\n",
    "        # Search recursively for MP4 files\n",
    "        pattern = f\"{ads_dir}/**/{commercial_number}.mp4\"\n",
    "        matches = glob.glob(pattern, recursive=True)\n",
    "        return matches[0] if matches else None\n",
    "    ad_df['ocr_text'] = ''\n",
    "    for idx, row in ad_df.iterrows():\n",
    "        commercial_number = row['commercial_number']\n",
    "        video_path = find_video_file(commercial_number, ads_dir)\n",
    "        \n",
    "        if video_path:\n",
    "            ocr_text = ocr(video_path)\n",
    "            ad_df.at[idx, 'ocr_text'] = ocr_text\n",
    "        else:\n",
    "            logging.info(f\"Video not found for commercial {commercial_number}\")\n",
    "\n",
    "    ad_df[['commercial_number', 'ocr_text']].to_csv('csvs/ocr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature: Superlatives, Comparatives, Uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transcript data\n",
    "ocr_df = pd.read_csv('csvs/ocr.csv')\n",
    "ad_df = ad_df.merge(ocr_df, on='commercial_number', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import text_analysis as ta\n",
    "if not BDM_WORDS_CHECKPOINT:\n",
    "\n",
    "\n",
    "    ad_df['word_count'] = 0\n",
    "    ad_df['superlative_count'] = 0\n",
    "    ad_df['superlative_pct'] = 0.0\n",
    "    ad_df['comparative_count'] = 0\n",
    "    ad_df['comparative_pct'] = 0.0\n",
    "    ad_df['uniqueness_count'] = 0\n",
    "    ad_df['uniqueness_pct'] = 0.0\n",
    "    ad_df['total_bdm_terms_count'] = 0\n",
    "    ad_df['total_bdm_terms_pct'] = 0.0\n",
    "\n",
    "    for idx, row in ad_df.iterrows():\n",
    "        word_count = len(ta.get_tokens(row['transcript']))\n",
    "        ad_df.at[idx, 'word_count'] = word_count\n",
    "\n",
    "        superlatives = ta.get_superlatives(row['transcript'])\n",
    "        ad_df.at[idx, 'superlatives'] = ', '.join(superlatives) if superlatives else ''\n",
    "        superlative_count = len(superlatives) if superlatives else 0\n",
    "        ad_df.at[idx, 'superlative_count'] = superlative_count\n",
    "\n",
    "        comparatives = ta.get_comparatives(row['transcript'])\n",
    "        ad_df.at[idx, 'comparatives'] = ', '.join(comparatives) if comparatives else ''\n",
    "        comparative_count = len(comparatives) if comparatives else 0\n",
    "        ad_df.at[idx, 'comparative_count'] = comparative_count\n",
    "        \n",
    "        unique_words = ta.get_unique_words(row['transcript'])\n",
    "        ad_df.at[idx, 'unique_words'] = ', '.join(unique_words) if unique_words else ''\n",
    "        uniqueness_count = len(unique_words) if unique_words else 0\n",
    "        ad_df.at[idx, 'uniqueness_count'] = uniqueness_count\n",
    "\n",
    "        if word_count > 0:\n",
    "            ad_df.at[idx, 'superlative_pct'] = superlative_count / word_count * 100\n",
    "            ad_df.at[idx, 'comparative_pct'] = comparative_count / word_count * 100\n",
    "            ad_df.at[idx, 'uniqueness_pct'] = uniqueness_count / word_count * 100\n",
    "            \n",
    "            total_bdm_terms = superlative_count + comparative_count + uniqueness_count\n",
    "            ad_df.at[idx, 'total_bdm_terms_count'] = total_bdm_terms\n",
    "            ad_df.at[idx, 'total_bdm_terms_pct'] = total_bdm_terms / word_count * 100\n",
    "\n",
    "    ad_df = ad_df.sort_values(\n",
    "        by=['superlative_count', 'comparative_count', 'superlative_pct', 'comparative_pct', 'uniqueness_pct'],\n",
    "        ascending=[False, False, False, False, False]\n",
    "    )\n",
    "\n",
    "    ad_df[['commercial_number', 'superlatives', 'comparatives', 'unique_words', 'superlative_count', 'comparative_count', 'uniqueness_count', 'superlative_pct', 'comparative_pct', 'uniqueness_pct', 'total_bdm_terms_count', 'total_bdm_terms_pct']].to_csv('csvs/bdm_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature: Nomen + Adjektive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdm_words_df = pd.read_csv('csvs/bdm_words.csv')\n",
    "ad_df = ad_df.merge(bdm_words_df, on='commercial_number', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ADJ_NOUN_PAIRS_CHECKPOINT:\n",
    "  ad_df[\"adj_noun_pairs\"] = ad_df[\"transcript\"].apply(ta.extract_adj_noun_pairs)\n",
    "  ad_df[\"num_adj_noun_pairs\"] = ad_df[\"adj_noun_pairs\"].apply(len)\n",
    "  ad_df[['commercial_number', 'adj_noun_pairs', 'num_adj_noun_pairs']].to_csv('csvs/adj_noun_pairs.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature: Semantische Nähe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_noun_pairs_df = pd.read_csv('csvs/adj_noun_pairs.csv')\n",
    "ad_df = ad_df.merge(adj_noun_pairs_df, on='commercial_number', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if INDUSTRY_SPECIFIC_AWARENESS and not SEMANTIC_SIMILARITY_CHECKPOINT:\n",
    "    import nltk\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.probability import FreqDist\n",
    "    from collections import defaultdict\n",
    "    nltk.download('all')\n",
    "    import numpy as np\n",
    "    for idx, row in ad_df.iterrows():\n",
    "        transcript = row['transcript']\n",
    "        product_cat_keyword_similarities = {}\n",
    "        for keyword in row['product_cat_keywords'][1:-1].replace(\"'\", \"\").split(\", \"):\n",
    "            similarity = round(float(ta.get_semantic_similarity(transcript, keyword)), 3)\n",
    "            product_cat_keyword_similarities[keyword] = similarity\n",
    "        \n",
    "        sorted_keywords = sorted(product_cat_keyword_similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_3_keywords = sorted_keywords[:3]\n",
    "        top_3_average = round(float(np.mean([sim for _, sim in top_3_keywords])), 3)\n",
    "        \n",
    "\n",
    "        logging.info(f\"Top 3 keywords for {row['commercial_number']}:\")\n",
    "        for keyword, similarity in top_3_keywords:\n",
    "            logging.info(f\"- {keyword}: {similarity}\")\n",
    "        logging.info(f\"Top 3 average similarity: {top_3_average}\")\n",
    "        \n",
    "        ad_df.at[idx, 'product_cat_keyword_similarity'] = top_3_average\n",
    "        ad_df.at[idx, 'product_cat_top_keywords'] = ', '.join([keyword for keyword, _ in top_3_keywords])\n",
    "if BRAND_SPECIFIC_AWARENESS and not SEMANTIC_SIMILARITY_CHECKPOINT:\n",
    "    for idx, row in ad_df.iterrows():\n",
    "        transcript = row['transcript']\n",
    "        product_brand_keyword_similarities = {}\n",
    "        \n",
    "        for keyword in row['product_brand_keywords'][1:-1].replace(\"'\", \"\").split(\", \"):\n",
    "            similarity = round(float(ta.get_semantic_similarity(transcript, keyword)), 3)\n",
    "            product_brand_keyword_similarities[keyword] = similarity\n",
    "        \n",
    "        sorted_keywords = sorted(product_brand_keyword_similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_3_keywords = sorted_keywords[:3]\n",
    "        top_3_average = round(float(np.mean([sim for _, sim in top_3_keywords])), 3)\n",
    "        \n",
    "        logging.info(f\"Top 3 brand keywords for {row['commercial_number']}:\")\n",
    "        for keyword, similarity in top_3_keywords:\n",
    "            logging.info(f\"- {keyword}: {similarity}\")\n",
    "        logging.info(f\"Top 3 average brand similarity: {top_3_average}\")\n",
    "        \n",
    "        ad_df.at[idx, 'product_brand_keyword_similarity'] = top_3_average\n",
    "        ad_df.at[idx, 'product_brand_top_keywords'] = ', '.join([keyword for keyword, _ in top_3_keywords])\n",
    "if not SEMANTIC_SIMILARITY_CHECKPOINT:\n",
    "    columns = ['commercial_number']\n",
    "    if INDUSTRY_SPECIFIC_AWARENESS:\n",
    "        columns.extend(['product_cat_keyword_similarity', 'product_cat_top_keywords'])\n",
    "    if BRAND_SPECIFIC_AWARENESS:\n",
    "        columns.extend(['product_brand_keyword_similarity', 'product_brand_top_keywords'])\n",
    "    ad_df[columns].to_csv('csvs/semantic_similarity.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature: Personalpronomen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_similarity_df = pd.read_csv('csvs/semantic_similarity.csv')\n",
    "ad_df = ad_df.merge(semantic_similarity_df, on='commercial_number', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not PERSONAL_PRONOUNS_CHECKPOINT:\n",
    "    for idx, row in ad_df.iterrows():\n",
    "        transcript = row['transcript']\n",
    "        most_common_pronoun, most_common_pronoun_count, most_common_pronoun_pct = ta.get_dominant_pronoun_stats(transcript)\n",
    "        ad_df.at[idx, 'most_common_pronoun'] = most_common_pronoun\n",
    "        ad_df.at[idx, 'most_common_pronoun_count'] = most_common_pronoun_count\n",
    "        ad_df.at[idx, 'most_common_pronoun_pct'] = most_common_pronoun_pct\n",
    "        ad_df[['commercial_number', 'most_common_pronoun', 'most_common_pronoun_count', 'most_common_pronoun_pct']].to_csv('csvs/personal_pronouns.csv', index=False)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_pronouns_df = pd.read_csv('csvs/personal_pronouns.csv')\n",
    "ad_df = ad_df.merge(personal_pronouns_df, on='commercial_number', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original columns before removal\n",
    "original_columns = ad_df.columns.tolist()\n",
    "\n",
    "# Remove columns which aren't numbers or categorical\n",
    "ad_df = ad_df.select_dtypes(include=['number', 'category'])\n",
    "\n",
    "# Determine which columns were removed\n",
    "removed_columns = [col for col in original_columns if col not in ad_df.columns]\n",
    "\n",
    "# Display removed columns\n",
    "print(\"Removed columns:\", removed_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(ad_df[ad_df.isnull().any(axis=1)])\n",
    "display(ad_df[ad_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Rows with BDM = 1.0: {len(ad_df[ad_df['BDM'] == 1.0])}\")\n",
    "logging.info(f\"Rows with BDM = 0.0: {len(ad_df[ad_df['BDM'] == 0.0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commercial_numbers = ad_df['commercial_number']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRISP-DM 4: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models as m\n",
    "\n",
    "data = m.prepare_model_data(ad_df, INDUSTRY_SPECIFIC_AWARENESS, BRAND_SPECIFIC_AWARENESS)\n",
    "target = ad_df['BDM']\n",
    "base_models = m.get_base_models()\n",
    "param_distributions = m.get_param_distributions()\n",
    "tuned_models = m.tune_models(data, target, base_models, param_distributions)\n",
    "\n",
    "trained_models = m.train_models(data, target, tuned_models, INDUSTRY_SPECIFIC_AWARENESS, BRAND_SPECIFIC_AWARENESS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRISP-DM 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df, predictions = m.evaluate_models(data, target, trained_models)\n",
    "original_data = ad_df.copy()\n",
    "display(original_data.head(10))\n",
    "original_data = pd.concat([original_data, predictions], axis=1)\n",
    "m.display_model_results(data, target, trained_models, results_df)\n",
    "predicted_data = original_data[['commercial_number', 'BDM', 'Logistic Regression_result', 'Random Forest_result', 'Support Vector Machine_result']]\n",
    "predicted_data['majority_vote'] = predicted_data[['Logistic Regression_result', 'Random Forest_result', 'Support Vector Machine_result']].mode(axis=1)[0]\n",
    "display(predicted_data.head(10))\n",
    "m.analyze_decision_tree(data, target, tuned_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

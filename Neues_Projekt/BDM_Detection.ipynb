{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting BDM In Superbowl Commercials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning Brands To Productcategories  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:54:59.389468Z",
     "iopub.status.busy": "2024-11-25T16:54:59.389384Z",
     "iopub.status.idle": "2024-11-25T16:54:59.556178Z",
     "shell.execute_reply": "2024-11-25T16:54:59.555869Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:54:59.573934Z",
     "iopub.status.busy": "2024-11-25T16:54:59.573769Z",
     "iopub.status.idle": "2024-11-25T16:54:59.846568Z",
     "shell.execute_reply": "2024-11-25T16:54:59.846263Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "BDM_excel= pd.read_excel(f\"{os.getenv(\"BDM_EXCEL_FILE\")}\")\n",
    "BDM_excel.head(30)\n",
    "final_excel = pd.read_excel(f\"{os.getenv(\"FINAL_EXCEL_FILE\")}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_excel = final_excel.merge(\n",
    "    BDM_excel[['AdNumber', 'BDM']], \n",
    "    on='AdNumber', \n",
    "    how='left',\n",
    "    suffixes=('_old', '')\n",
    ").drop('BDM_old', axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:54:59.848002Z",
     "iopub.status.busy": "2024-11-25T16:54:59.847732Z",
     "iopub.status.idle": "2024-11-25T16:54:59.853603Z",
     "shell.execute_reply": "2024-11-25T16:54:59.853387Z"
    }
   },
   "outputs": [],
   "source": [
    "ad_df = final_excel.groupby(['cont_primary_product_type', 'BRAND', 'AdNumber', \"BDM\"]).size().reset_index(name='count')\n",
    "ad_df.rename(columns={'cont_primary_product_type': 'product_category', 'BRAND': 'brand', 'AdNumber': 'commercial_number'}, inplace=True)\n",
    "ad_df.drop(columns=['count'], inplace=True)\n",
    "ad_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:54:59.854422Z",
     "iopub.status.busy": "2024-11-25T16:54:59.854349Z",
     "iopub.status.idle": "2024-11-25T16:54:59.878539Z",
     "shell.execute_reply": "2024-11-25T16:54:59.878254Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Get all txt files recursively from ADS_DIR\n",
    "ads_dir = Path(os.getenv(\"ADS_DIR\"))\n",
    "transcript_files = glob.glob(str(ads_dir / \"**/*.txt\"), recursive=True)\n",
    "# print transcript_files\n",
    "print(transcript_files)\n",
    "# Create a dictionary mapping commercial numbers to file paths\n",
    "transcript_map = {Path(f).stem: f for f in transcript_files}\n",
    "\n",
    "# Update transcripts in dataframe\n",
    "ad_df['transcript'] = ''\n",
    "for idx, row in ad_df.iterrows():\n",
    "    commercial_num = row['commercial_number']\n",
    "    if commercial_num in transcript_map:\n",
    "        try:\n",
    "            with open(transcript_map[commercial_num], 'r', encoding='utf-8') as f:\n",
    "                ad_df.at[idx, 'transcript'] = f.read().strip()\n",
    "        except FileNotFoundError:\n",
    "            ad_df.at[idx, 'transcript'] = None\n",
    "    else:\n",
    "        ad_df.at[idx, 'transcript'] = None\n",
    "\n",
    "ad_df[ad_df['transcript'].notna()]\n",
    "ad_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract most frequent Keywords for each Brand from trasncript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:54:59.879441Z",
     "iopub.status.busy": "2024-11-25T16:54:59.879371Z",
     "iopub.status.idle": "2024-11-25T16:54:59.889704Z",
     "shell.execute_reply": "2024-11-25T16:54:59.889483Z"
    }
   },
   "outputs": [],
   "source": [
    "brand_df = ad_df.groupby('brand').agg({\n",
    "    'transcript': lambda x: '\\n\\n'.join(str(t) for t in x if pd.notna(t)),\n",
    "    'commercial_number': lambda x: list(x),  # collect all ad numbers\n",
    "}).reset_index()\n",
    "\n",
    "# Add number of ads column\n",
    "brand_df['number_of_ads'] = brand_df['commercial_number'].str.len()\n",
    "\n",
    "# Reorder columns and sort by number_of_ads\n",
    "brand_df = brand_df[['brand', 'number_of_ads', 'commercial_number', 'transcript']].sort_values(\n",
    "    by='number_of_ads', \n",
    "    ascending=False\n",
    ")\n",
    "brand_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:54:59.890511Z",
     "iopub.status.busy": "2024-11-25T16:54:59.890442Z",
     "iopub.status.idle": "2024-11-25T16:55:01.157765Z",
     "shell.execute_reply": "2024-11-25T16:55:01.157371Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "\n",
    "nltk.download('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:55:01.158841Z",
     "iopub.status.busy": "2024-11-25T16:55:01.158709Z",
     "iopub.status.idle": "2024-11-25T16:55:01.308859Z",
     "shell.execute_reply": "2024-11-25T16:55:01.308512Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_top_keywords(transcript, num_keywords=10):\n",
    "    if pd.isna(transcript):\n",
    "        return \"\"\n",
    "    \n",
    "    # Tokenize and convert to lowercase\n",
    "    tokens = word_tokenize(transcript.lower())\n",
    "    \n",
    "    # Enhanced stopwords - remove common commercial words that aren't BDM-related\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    commercial_stopwords = {'like', 'get', 'one', 'now', 'see', 'look', 'come', 'go'}\n",
    "    stop_words.update(commercial_stopwords)\n",
    "    \n",
    "    # Keep only meaningful words and potential phrases\n",
    "    tokens = [word for word in tokens if (\n",
    "        word.isalnum() and \n",
    "        word not in stop_words and\n",
    "        len(word) > 2  # Remove very short words\n",
    "    )]\n",
    "    \n",
    "    # Get frequency distribution\n",
    "    fdist = FreqDist(tokens)\n",
    "    \n",
    "    # Include frequency to help identify emphasis\n",
    "    top_keywords = [f\"{word} ({freq})\" for word, freq in fdist.most_common(num_keywords)]\n",
    "    return ', '.join(top_keywords)\n",
    "# TODO: Replace with actual manually selected keywords\n",
    "brand_df['transcript_keywords'] = brand_df['transcript'].apply(extract_top_keywords)\n",
    "# add a column for manually selected keywords, make it empty for now\n",
    "brand_df['manually_selected_keywords'] = ''\n",
    "brand_df.loc[brand_df['brand'] == 'AvocadosfromMexico', 'manually_selected_keywords'] = 'fresh avocados, authentic Mexican flavor, healthy snack, versatile, green gold, Mexican avocados, avocado recipes, nutrient-rich, healthy fats, premium quality, farm to table, rich in fiber, natural, creamy texture, avocado lovers, guacamole, farm fresh, sustainable farming, avocado health benefits, heart-healthy, clean eating, avocado toast, fresh ingredients, Mexican agriculture, rich taste, sustainable, healthy lifestyle, Mexican heritage, protein-rich, gluten-free, non-GMO, best avocados'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'CocaCola', 'manually_selected_keywords'] = 'classic cola, refreshing, Coca-Cola taste, soda, iconic drink, carbonated beverage, sweet refreshment, Coca-Cola experience, soda culture, family-friendly, original formula, Coca-Cola Zero, taste of happiness, joyful moments, Coca-Cola taste test, global brand, quench thirst, cola drink, refreshing soda, caffeine boost, nostalgia, tradition, great taste, pop culture, Coca-Cola family, carbonated refreshment, classic flavor, cool drink, all-time favorite, global reach, social moments, refreshment moments'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'Doritos', 'manually_selected_keywords'] = 'bold flavor, crunchy snack, snack time, Doritos crunch, nacho cheese, tortilla chips, bold taste, snack attack, cheesy, bold chips, extreme flavor, Doritos flavor, signature snack, bold chips, spicy chips, Doritos dip, snack culture, Fiesta, snack lovers, party snack, tortilla chip, cheese lovers, snackable, bagged chips, bold snack, epic flavor, nacho lovers, bold spices, cheesy snack, intense flavor, snack obsession, snack innovation, Doritos taco'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'Pepsi', 'manually_selected_keywords'] = 'refreshing, Pepsi generation, bold flavors, cola, better taste, Pepsi challenge, carbonated beverage, Pepsi vs Coke, great taste, drink Pepsi, PepsiCo, unique formula, original soda, sugary drink, classic soda, sweet taste, flavor boost, thirst-quenching, family-friendly, fun beverage, Pepsi moments, summer drinks, carbonated refreshment, drink refreshment, youth culture, new flavors, taste test, Pepsi flavors, cool drinks, sports sponsorship, pop culture, refreshing drink, Pepsi Zero'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'Pringles', 'manually_selected_keywords'] = 'stackable chips, crisp texture, Pringles crunch, fun snack, potato crisps, unique packaging, endless flavor combinations, chip innovation, Pringles variety, perfect crunch, Pringles flavors, satisfying snack, snackable, Pringles moments, can-shaped packaging, thin crispy chips, chips lovers, snack cravings, flavor-packed, family snack, Pringles party size, potato chips, snack time, variety packs, Pringles classic, flavor-packed crisps, irresistibly crunchy, Pringles chips, crispy texture, unique snack, on-the-go snack'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'Snickers', 'manually_selected_keywords'] = 'hungry, satisfy hunger, chocolate bar, peanuts, caramel, Snickers satisfaction, chocolate lovers, energy boost, satisfying snack, indulgent treat, hunger cure, sweet snack, Snickers candy, full satisfaction, sweet chocolate, peanut-filled, caramel center, peanut snack, Snickers moments, hunger solution, snack break, chocolate cravings, Snickers bites, energizing chocolate, hunger pangs, fun size, treat yourself, snackable chocolate, premium chocolate, candy bar, indulgence, ultimate chocolate'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'WonderfulPistachios', 'manually_selected_keywords'] = 'healthy snack, pistachios, nut lovers, protein-rich, snackable, roasted pistachios, heart-healthy, natural snack, high in fiber, superfood snack, Wonderful nuts, California pistachios, healthy fats, clean snack, green nuts, sustainable farming, premium pistachios, plant-based protein, guilt-free snack, roasted nuts, fiber-rich, energy boost, snack with benefits, healthy lifestyle, on-the-go snack, crunchy pistachios, Wonderful brand, nut benefits, weight management, heart health, antioxidant-rich, nutty goodness'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'BudLight', 'manually_selected_keywords'] = 'refreshing beer, light beer, crisp taste, easy-drinking, Bud Light taste, casual beer, beer lovers, refreshing lager, smooth beer, Bud Light experience, perfect for parties, beer with friends, light refreshment, crisp lager, Bud Light flavor, low-calorie beer, beer culture, popular beer, go-to beer, drink responsibly, chill moments, beer variety, low-carb beer, brewmaster, light lager, beer enjoyment, Bud Light moments, thirst-quenching beer, party beer, American lager, easy-going beer'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'Budweiser', 'manually_selected_keywords'] = 'king of beers, American beer, full-flavored lager, classic beer, Budweiser taste, beer heritage, iconic beer, beer lovers, best lager, bold beer, smooth finish, premium beer, refreshing lager, American brewing, original Budweiser, thirst-quenching, rich taste, brewmasters, full-bodied beer, crisp refreshment, golden beer, beer culture, American-made, beer brand, top beer, Budweiser experience, great beer, beer quality, rich flavors, beer moments, party beer, legendary beer'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'MichelobULTRA', 'manually_selected_keywords'] = 'low-calorie beer, fitness beer, light lager, refreshing, Michelob ULTRA taste, active lifestyle, ultra-refreshing, premium light beer, healthy beer choice, crisp lager, clean beer, Michelob experience, Michelob ULTRA flavor, superior taste, low-carb beer, alcohol-free, beer for athletes, light refreshment, golden beer, refreshing lager, fit beer, best light beer, healthy drinking, active refreshment, calorie-conscious, fitness-friendly beer, Michelob brand, balanced beer, smooth beer, refreshing beer, sports beer, ultra-refreshing'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'Audi', 'manually_selected_keywords'] = 'luxury cars, innovative technology, quattro all-wheel drive, precision engineering, performance, premium interiors, Audi design, advanced safety, cutting-edge technology, high-performance, quattro system, Audi TT, stylish cars, eco-friendly Audi, hybrid models, driving experience, high-end vehicles, sophisticated design, iconic cars, luxury sedans, sport cars, luxury SUVs, digital cockpit, precision engineering, top-tier performance, ultimate driving experience, car enthusiasts, sleek design, Audi A4, car luxury, refined craftsmanship, performance engineering'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'Hyundai', 'manually_selected_keywords'] = 'affordable cars, innovative designs, Hyundai SUV, eco-friendly vehicles, advanced tech, reliable performance, value for money, hybrid cars, fuel-efficient, safety features, compact cars, family-friendly vehicles, clean energy cars, reliable vehicles, smart technology, modern interiors, efficient design, comfort, affordable SUVs, Hyundai Santa Fe, electric cars, futuristic tech, long warranty, connected cars, top safety ratings, cutting-edge designs, urban mobility, efficient driving, fuel economy, Hyundai Elantra, best warranty, future-driven'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'Jeep', 'manually_selected_keywords'] = 'off-road vehicles, rugged design, adventure-ready, Jeep experience, all-terrain, iconic SUV, 4x4, Jeep Wrangler, tough vehicles, outdoor adventure, Jeep off-roading, reliable 4WD, adventure culture, Jeep power, rugged reliability, tough performance, Jeep Cherokee, adventure seekers, off-road enthusiast, Jeep spirit, SUV performance, outdoor lifestyle, Jeep Trailhawk, all-wheel drive, wilderness exploration, Jeep adventure, off-road dominance, Jeep heritage, off-road thrill, Jeep Gladiator, outdoor freedom'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'Kia', 'manually_selected_keywords'] = 'affordable cars, modern design, reliable vehicles, eco-friendly cars, Kia SUV, smart tech, budget-friendly, safety features, efficient performance, hybrid models, stylish cars, advanced technology, Kia experience, comfortable driving, family-friendly cars, great warranties, high performance, Kia Sportage, cutting-edge design, fuel-efficient vehicles, fun-to-drive cars, low-cost maintenance, futuristic car models, Kia Forte, well-equipped cars, tech-savvy, sleek vehicles, efficient fuel economy, user-friendly tech, Kia Sorento'\n",
    "\n",
    "brand_df.loc[brand_df['brand'] == 'Toyota', 'manually_selected_keywords'] = 'reliable cars, durable vehicles, Toyota innovation, hybrid cars, fuel-efficient, eco-friendly cars, Toyota SUVs, advanced safety, Toyota Camry, trusted performance, quality engineering, all-wheel drive, cutting-edge tech, Toyota Corolla, best-selling car, fuel-efficient vehicles, Toyota Prius, hybrid technology, smart safety features, comfort-driven, family-friendly vehicles, rugged trucks, advanced engineering, Toyota Tacoma, dependable cars, Toyota Tundra, high performance, quality craftsmanship, top safety ratings, efficient driving, sustainable transportation'\n",
    "\n",
    "brand_df = brand_df.head(30)\n",
    "brand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T16:55:01.309804Z",
     "iopub.status.busy": "2024-11-25T16:55:01.309730Z",
     "iopub.status.idle": "2024-11-25T16:55:09.727108Z",
     "shell.execute_reply": "2024-11-25T16:55:09.726758Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "#TODO: REmove later on, -  drop any rows where manually_selected_keywords is empty or an empty string or whatever\n",
    "brand_df = brand_df[brand_df['manually_selected_keywords'].notna()]\n",
    "brand_df = brand_df[brand_df['manually_selected_keywords'] != '']\n",
    "# TODO: Remove later on, - drop any rows from ad_df where transcript is empty or an empty string or whatever\n",
    "ad_df = ad_df[ad_df['transcript'].notna()]\n",
    "ad_df = ad_df[ad_df['transcript'] != '']\n",
    "# Create a dictionary mapping brands to their keywords for quick lookup\n",
    "brand_keywords_dict = dict(zip(brand_df['brand'], brand_df['manually_selected_keywords']))\n",
    "\n",
    "# Initialize the model outside the loop for better performance\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Add similarity score column to ad_df\n",
    "ad_df['keyword_similarity'] = None\n",
    "\n",
    "# Calculate similarity for each ad\n",
    "for idx, row in ad_df.iterrows():\n",
    "    if pd.isna(row['transcript']) or row['brand'] not in brand_keywords_dict:\n",
    "        continue\n",
    "        \n",
    "    keywords = brand_keywords_dict[row['brand']]\n",
    "    transcript = row['transcript']\n",
    "    \n",
    "    # Get embeddings\n",
    "    transcript_embedding = model.encode([transcript])\n",
    "    keyword_embedding = model.encode([keywords])\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarity = cosine_similarity(transcript_embedding, keyword_embedding)[0][0]\n",
    "    ad_df.at[idx, 'keyword_similarity'] = similarity\n",
    "    \n",
    "    # Print details where similarity is found\n",
    "    print(f\"Brand: {row['brand']}\")\n",
    "    print(f\"Transcript: {transcript}\")\n",
    "    print(f\"Keywords: {keywords}\")\n",
    "    print(f\"Similarity: {similarity}\\n\")\n",
    "\n",
    "# Display results\n",
    "#get rid of any rows with missing values in transcript column\n",
    "ad_df = ad_df.dropna(subset=['transcript'])\n",
    "# TODO: Remove later on\n",
    "# drop rows where keyword_similarity is 1.0\n",
    "ad_df = ad_df[ad_df['keyword_similarity'] != 1.0]\n",
    "# sort by highest similarity\n",
    "ad_df = ad_df.sort_values(by='keyword_similarity', ascending=False)\n",
    "ad_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ansatz 1 (Machine learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Prepare features\n",
    "X = ad_df[['keyword_similarity']].copy()\n",
    "y = ad_df['BDM'].astype(float)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Balance the dataset using undersampling\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_balanced, y_balanced = undersampler.fit_resample(X, y)\n",
    "\n",
    "# Split the balanced data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Random Forest (no need for class_weight now since data is balanced)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=42)\n",
    "\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "# Get dummy predictions\n",
    "dummy_pred = dummy.predict(X_test)\n",
    "dummy_pred_proba = dummy.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics for both models\n",
    "print(\"Random Forest Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(\"\\nDetailed Classification Report (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nDummy Classifier Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, dummy_pred):.3f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, dummy_pred_proba):.3f}\")\n",
    "print(\"\\nDetailed Classification Report (Dummy):\")\n",
    "print(classification_report(y_test, dummy_pred))\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importance_df)\n",
    "print(\"\\nOriginal BDM Distribution:\")\n",
    "bdm_counts = y.value_counts()\n",
    "print(f\"BDM = 0: {bdm_counts[0]} rows\")\n",
    "print(f\"BDM = 1: {bdm_counts[1]} rows\")\n",
    "print(f\"Total: {len(y)} rows\")\n",
    "print(f\"Percentage of BDM=1: {(bdm_counts[1]/len(y))*100:.1f}%\")\n",
    "\n",
    "print(\"\\nBalanced BDM Distribution:\")\n",
    "balanced_counts = y_balanced.value_counts()\n",
    "print(f\"BDM = 0: {balanced_counts[0]} rows\")\n",
    "print(f\"BDM = 1: {balanced_counts[1]} rows\")\n",
    "print(f\"Total: {len(y_balanced)} rows\")\n",
    "print(f\"Percentage of BDM=1: {(balanced_counts[1]/len(y_balanced))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ansatz 2 (Deep learning) ~ Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "# 2. Dataset class for PyTorch\n",
    "class AdDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        transcript = self.dataframe.iloc[index][\"transcript\"]\n",
    "        label = self.dataframe.iloc[index][\"BDM\"]\n",
    "        inputs = self.tokenizer(transcript, padding='max_length', max_length=self.max_len, truncation=True, return_tensors=\"pt\")\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 3. Tokenizer and Dataset Preparation\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "dataset = AdDataset(ad_df, tokenizer, max_len=128)\n",
    "\n",
    "# Split into train and test datasets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# 4. Model Setup\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 5. Training Loop\n",
    "def train_model():\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Training for 3 epochs\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                labels=batch['labels']\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Train the model\n",
    "train_model()\n",
    "\n",
    "# 6. Evaluation Function\n",
    "def evaluate_model():\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask']\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).detach().cpu().numpy()\n",
    "            labels = batch['labels'].detach().cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels)\n",
    "\n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    print(f\"Accuracy: {acc:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    # roc auc score\n",
    "    roc_auc = roc_auc_score(true_labels, predictions)\n",
    "    print(f\"ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BDM_Detection-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

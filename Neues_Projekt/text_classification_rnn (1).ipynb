{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4n9TsbGw-f"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "0nbI5DtDGw-i"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TnJztDZGw-n"
      },
      "source": [
        "# Text classification with an RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfN3bMR5Gw-o"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/text/tutorials/text_classification_rnn\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_classification_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/text_classification_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/text/docs/tutorials/text_classification_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUWearf0Gw-p"
      },
      "source": [
        "This text classification tutorial trains a [recurrent neural network](https://developers.google.com/machine-learning/glossary/#recurrent_neural_network) on the [IMDB large movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/) for sentiment analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2VQo4bajwUU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z682XYsrjkY9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/arkastor/Development/Commercial-Brand-Differentiating-Message-Analysis/Neues_Projekt/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2024-12-15 20:33:16.207176: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-15 20:33:16.208238: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-12-15 20:33:16.228244: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-12-15 20:33:16.228741: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-15 20:33:16.560945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rXHa-w9JZhb"
      },
      "source": [
        "Import `matplotlib` and create a helper function to plot graphs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Mp1Z7P9pYRSK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRmMubr0jrE2"
      },
      "source": [
        "## Setup input pipeline\n",
        "\n",
        "\n",
        "The IMDB large movie review dataset is a *binary classification* datasetâ€”all the reviews have either a *positive* or *negative* sentiment.\n",
        "\n",
        "Download the dataset using [TFDS](https://www.tensorflow.org/datasets). See the [loading text tutorial](https://www.tensorflow.org/tutorials/load_data/text) for details on how to load this sort of data manually.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHRwRoP2nVHX",
        "outputId": "f7e6bb48-a3c1-4324-884c-6e5e2edd3611"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-15 20:33:17.271858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-12-15 20:33:17.362854: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "train_dataset.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWA4c2ir7g6p"
      },
      "source": [
        "Initially this returns a dataset of (text, label pairs):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd4_BGKyurao",
        "outputId": "3642b0fb-8018-4a4f-f327-2c7bbf6b023b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
            "label:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-15 20:33:17.435654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
            "\t [[{{node Placeholder/_1}}]]\n",
            "2024-12-15 20:33:17.435819: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
            "\t [[{{node Placeholder/_4}}]]\n",
            "2024-12-15 20:33:17.457499: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        }
      ],
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', label.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2qVJzcEluH_"
      },
      "source": [
        "Next shuffle the data for training and create batches of these `(text, label)` pairs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dDsCaZCDYZgm"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VznrltNOnUc5"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqkvdcFv41wC",
        "outputId": "13d6803d-c599-4491-877a-27c25d586d88"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-15 20:33:17.504717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
            "\t [[{{node Placeholder/_3}}]]\n",
            "2024-12-15 20:33:17.505126: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
            "\t [[{{node Placeholder/_4}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "texts:  [b'Cor blimey. This film really surprised me as it is a comedy masterpiece. Billy Zane is stunning as the central character, and everyone manages to play it straight enough for the comedy to be natural and easy.<br /><br />The soundtrack is really good, and the set pieces are a joy to behold. I recommend that you watch this film with a bunch of mates, a few bottles of your liquor of choice, and prepare to be astonished and highly entertained.<br /><br />This carries on so perfectly from kitsch masterpieces like Plan 9 From Outer Space that it is in the true \"B\" movie tradition. But what makes it more than that is the caliber of the people who took part in the film. Ron Pearlman for example. I still find my self giggling at the scene where Zane prances down a set of steps for no apparent reason in an almost ballet style. All a bit mad, and all the better for it.'\n",
            " b'All I can say about the Necromaniac/Schizophreniac 2 series is... if you are even remotely \"PC\" or don\\'t have a seriously messed up sense of humor, then you probably wont get it. As sick and disgusting as this movie is, it really is a comedy and not a \"horror\" movie at all. If you can appreciate somebody who pushes the bounds of good taste and political correctness to the most extreme limits imaginable, to the point where is becomes so out of hand that it\\'s comical, then you must see this to believe it. This movie is so out of control that a major film studio couldn\\'t touch this with a 10 foot pole (with a condom on the end). In my opinion though, the best, most extreme pieces of art come from way underground. If you don\\'t stick to the same old formula that people are used to seeing, then they reject it.<br /><br />I have seen stacks of terrible, boring, z-grade, Indy movies that were just a waste of a perfectly good VHS tape or DVD-R. I have also seen stacks of stink bombs coming from the big named studios that were a complete waste of millions of dollars. When a NO BUDGET film like these two from Ron Atkins/John Giancaspro come out and blow all of the other \"shock\" films completely out of the water, you really have to take a second look at the whole Indy movie scene. After seeing this, you can really see how much freedom an Indy film maker can have when they work on their own.<br /><br />The funny thing is, even the other people who saw this movie and \"hated it\" admit to the fact that they laughed all the way through it. I don\\'t think that is is possible for anybody to get bored watching either of these two. So if don\\'t take everything that you seen in the mainstream media too seriously, and are able to laugh at a misanthropic, puppet wielding psychopath who has finally snapped, YOU HAVE TO SEE THIS. You may just be able to see it for the stand alone, cult classic that it is. Both Schizophreniac / Schizophreniac 2 are among the favorites in my collection of well over 1000 dvds.'\n",
            " b'This film is absolutely stunning. A new Blade Runner - future noir at it\\'s most gritty. The vision of Paris is superb, both recognisable and visionary, with sweeping vistas, grungy set pieces and futuristic virtual reality.<br /><br />The story line is quite simple, with few surprises, but that\\'s not what I like most about the film. It is a visual treat. <br /><br />Done in 3D and rendered in black and white (no greys!) with only one short spot of colour, it is less hard on the eyes than it sounds. There are many \"arty\" camera shots - closeups and odd viewpoints - but that just adds to the temperament of the film. Overall you get the impression of a graphic novel in footage form.<br /><br />I was initially under the impression that the film had been rotoscoped, such was the level of animation and high detail in the character\\'s facial expressions. But unlike \"A Scanner Darkly\" - which suffers from (or indeed is enhanced by) inconsistent character definition (just watch the way some of the hair changes shape!) - Renaissance is consistent and precise throughout. When the character is in close-up, added details and texture can bee seen, but when in mid-shot or further away details are omitted, but not to the detriment of character definition.<br /><br />For me, the only down side of the film is that in one commentary we are told that this is a one-off project. Such a shame, as I would like to see more of this futuristic film-noir storyline and especially in this cutting-edge graphic style.<br /><br />Oh, and the English dub is great too.<br /><br />All in all a great film and highly recommended.']\n",
            "\n",
            "labels:  [1 1 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-15 20:33:17.616539: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        }
      ],
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('texts: ', example.numpy()[:3])\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5eWCo88voPY"
      },
      "source": [
        "## Create the text encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFevcItw15P_"
      },
      "source": [
        "The raw text loaded by `tfds` needs to be processed before it can be used in a model. The simplest way to process text for training is using the `TextVectorization` layer. This layer has many capabilities, but this tutorial sticks to the default behavior.\n",
        "\n",
        "Create the layer, and pass the dataset's text to the layer's `.adapt` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uC25Lu1Yvuqy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-15 20:33:17.644329: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2024-12-15 20:33:17.644533: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ],
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuQzVBbe3Ldu"
      },
      "source": [
        "The `.adapt` method sets the layer's vocabulary. Here are the first 20 tokens. After the padding and unknown tokens they're sorted by frequency:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBoyjjWg0Ac9",
        "outputId": "5be63f01-0ee5-44a8-ba14-86ad43d0addb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
              "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
              "      dtype='<U14')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjId5pua3jHQ"
      },
      "source": [
        "Once the vocabulary is set, the layer can encode text into indices. The tensors of indices are 0-padded to the longest sequence in the batch (unless you set a fixed `output_sequence_length`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGc7C9WiwRWs",
        "outputId": "388fcf1f-39fb-412e-c910-bc51c44f2d18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1,  1, 11, ...,  0,  0,  0],\n",
              "       [32, 10, 69, ...,  0,  0,  0],\n",
              "       [11, 20,  7, ...,  0,  0,  0]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_example = encoder(example)[:3].numpy()\n",
        "encoded_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5cjz0bS39IN"
      },
      "source": [
        "With the default settings, the process is not completely reversible. There are three main reasons for that:\n",
        "\n",
        "1. The default value for `preprocessing.TextVectorization`'s `standardize` argument is `\"lower_and_strip_punctuation\"`.\n",
        "2. The limited vocabulary size and lack of character-based fallback results in some unknown tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_tD0QY5wXaK",
        "outputId": "6786d48e-beb1-400e-e50f-d9d38e9ecff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  b'Cor blimey. This film really surprised me as it is a comedy masterpiece. Billy Zane is stunning as the central character, and everyone manages to play it straight enough for the comedy to be natural and easy.<br /><br />The soundtrack is really good, and the set pieces are a joy to behold. I recommend that you watch this film with a bunch of mates, a few bottles of your liquor of choice, and prepare to be astonished and highly entertained.<br /><br />This carries on so perfectly from kitsch masterpieces like Plan 9 From Outer Space that it is in the true \"B\" movie tradition. But what makes it more than that is the caliber of the people who took part in the film. Ron Pearlman for example. I still find my self giggling at the scene where Zane prances down a set of steps for no apparent reason in an almost ballet style. All a bit mad, and all the better for it.'\n",
            "Round-trip:  [UNK] [UNK] this film really surprised me as it is a comedy [UNK] [UNK] [UNK] is [UNK] as the [UNK] character and everyone manages to play it straight enough for the comedy to be [UNK] and [UNK] br the soundtrack is really good and the set [UNK] are a [UNK] to [UNK] i recommend that you watch this film with a bunch of [UNK] a few [UNK] of your [UNK] of [UNK] and [UNK] to be [UNK] and highly [UNK] br this [UNK] on so perfectly from [UNK] [UNK] like [UNK] [UNK] from [UNK] space that it is in the true b movie [UNK] but what makes it more than that is the [UNK] of the people who took part in the film [UNK] [UNK] for example i still find my [UNK] [UNK] at the scene where [UNK] [UNK] down a set of [UNK] for no [UNK] reason in an almost [UNK] style all a bit [UNK] and all the better for it                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
            "\n",
            "Original:  b'All I can say about the Necromaniac/Schizophreniac 2 series is... if you are even remotely \"PC\" or don\\'t have a seriously messed up sense of humor, then you probably wont get it. As sick and disgusting as this movie is, it really is a comedy and not a \"horror\" movie at all. If you can appreciate somebody who pushes the bounds of good taste and political correctness to the most extreme limits imaginable, to the point where is becomes so out of hand that it\\'s comical, then you must see this to believe it. This movie is so out of control that a major film studio couldn\\'t touch this with a 10 foot pole (with a condom on the end). In my opinion though, the best, most extreme pieces of art come from way underground. If you don\\'t stick to the same old formula that people are used to seeing, then they reject it.<br /><br />I have seen stacks of terrible, boring, z-grade, Indy movies that were just a waste of a perfectly good VHS tape or DVD-R. I have also seen stacks of stink bombs coming from the big named studios that were a complete waste of millions of dollars. When a NO BUDGET film like these two from Ron Atkins/John Giancaspro come out and blow all of the other \"shock\" films completely out of the water, you really have to take a second look at the whole Indy movie scene. After seeing this, you can really see how much freedom an Indy film maker can have when they work on their own.<br /><br />The funny thing is, even the other people who saw this movie and \"hated it\" admit to the fact that they laughed all the way through it. I don\\'t think that is is possible for anybody to get bored watching either of these two. So if don\\'t take everything that you seen in the mainstream media too seriously, and are able to laugh at a misanthropic, puppet wielding psychopath who has finally snapped, YOU HAVE TO SEE THIS. You may just be able to see it for the stand alone, cult classic that it is. Both Schizophreniac / Schizophreniac 2 are among the favorites in my collection of well over 1000 dvds.'\n",
            "Round-trip:  all i can say about the [UNK] 2 series is if you are even [UNK] [UNK] or dont have a seriously [UNK] up sense of humor then you probably wont get it as [UNK] and [UNK] as this movie is it really is a comedy and not a horror movie at all if you can [UNK] [UNK] who [UNK] the [UNK] of good [UNK] and political [UNK] to the most [UNK] [UNK] [UNK] to the point where is becomes so out of hand that its [UNK] then you must see this to believe it this movie is so out of [UNK] that a major film [UNK] couldnt [UNK] this with a 10 [UNK] [UNK] with a [UNK] on the end in my opinion though the best most [UNK] [UNK] of art come from way [UNK] if you dont [UNK] to the same old [UNK] that people are used to seeing then they [UNK] itbr br i have seen [UNK] of terrible boring [UNK] [UNK] movies that were just a waste of a perfectly good [UNK] [UNK] or [UNK] i have also seen [UNK] of [UNK] [UNK] coming from the big named [UNK] that were a complete waste of [UNK] of [UNK] when a no budget film like these two from [UNK] [UNK] [UNK] come out and [UNK] all of the other [UNK] films completely out of the [UNK] you really have to take a second look at the whole [UNK] movie scene after seeing this you can really see how much [UNK] an [UNK] film [UNK] can have when they work on their [UNK] br the funny thing is even the other people who saw this movie and [UNK] it admit to the fact that they [UNK] all the way through it i dont think that is is possible for [UNK] to get [UNK] watching either of these two so if dont take everything that you seen in the [UNK] [UNK] too seriously and are able to laugh at a [UNK] [UNK] [UNK] [UNK] who has finally [UNK] you have to see this you may just be able to see it for the stand alone [UNK] classic that it is both [UNK] [UNK] 2 are among the [UNK] in my [UNK] of well over [UNK] [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "\n",
            "Original:  b'This film is absolutely stunning. A new Blade Runner - future noir at it\\'s most gritty. The vision of Paris is superb, both recognisable and visionary, with sweeping vistas, grungy set pieces and futuristic virtual reality.<br /><br />The story line is quite simple, with few surprises, but that\\'s not what I like most about the film. It is a visual treat. <br /><br />Done in 3D and rendered in black and white (no greys!) with only one short spot of colour, it is less hard on the eyes than it sounds. There are many \"arty\" camera shots - closeups and odd viewpoints - but that just adds to the temperament of the film. Overall you get the impression of a graphic novel in footage form.<br /><br />I was initially under the impression that the film had been rotoscoped, such was the level of animation and high detail in the character\\'s facial expressions. But unlike \"A Scanner Darkly\" - which suffers from (or indeed is enhanced by) inconsistent character definition (just watch the way some of the hair changes shape!) - Renaissance is consistent and precise throughout. When the character is in close-up, added details and texture can bee seen, but when in mid-shot or further away details are omitted, but not to the detriment of character definition.<br /><br />For me, the only down side of the film is that in one commentary we are told that this is a one-off project. Such a shame, as I would like to see more of this futuristic film-noir storyline and especially in this cutting-edge graphic style.<br /><br />Oh, and the English dub is great too.<br /><br />All in all a great film and highly recommended.'\n",
            "Round-trip:  this film is absolutely [UNK] a new [UNK] [UNK] future [UNK] at its most [UNK] the [UNK] of [UNK] is superb both [UNK] and [UNK] with [UNK] [UNK] [UNK] set [UNK] and [UNK] [UNK] [UNK] br the story line is quite simple with few [UNK] but thats not what i like most about the film it is a [UNK] [UNK] br br done in [UNK] and [UNK] in black and white no [UNK] with only one short [UNK] of [UNK] it is less hard on the eyes than it sounds there are many [UNK] camera shots [UNK] and [UNK] [UNK] but that just [UNK] to the [UNK] of the film overall you get the [UNK] of a [UNK] novel in footage [UNK] br i was [UNK] under the [UNK] that the film had been [UNK] such was the level of animation and high [UNK] in the characters [UNK] [UNK] but unlike a [UNK] [UNK] which [UNK] from or indeed is [UNK] by [UNK] character [UNK] just watch the way some of the [UNK] [UNK] [UNK] [UNK] is [UNK] and [UNK] throughout when the character is in [UNK] [UNK] [UNK] and [UNK] can [UNK] seen but when in [UNK] or [UNK] away [UNK] are [UNK] but not to the [UNK] of character [UNK] br for me the only down side of the film is that in one [UNK] we are told that this is a [UNK] [UNK] such a shame as i would like to see more of this [UNK] [UNK] storyline and especially in this [UNK] [UNK] [UNK] br oh and the english [UNK] is great [UNK] br all in all a great film and highly [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for n in range(3):\n",
        "  print(\"Original: \", example[n].numpy())\n",
        "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjUqGVBxGw-t"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7zsmInBOCPO"
      },
      "source": [
        "![A drawing of the information flow in the model](https://github.com/tensorflow/text/blob/master/docs/tutorials/images/bidirectional.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgs6nnSTGw-t"
      },
      "source": [
        "Above is a diagram of the model.\n",
        "\n",
        "1. This model can be build as a `tf.keras.Sequential`.\n",
        "\n",
        "2. The first layer is the `encoder`, which converts the text to a sequence of token indices.\n",
        "\n",
        "3. After the encoder is an embedding layer. An embedding layer stores one vector per word. When called, it converts the sequences of word indices to sequences of vectors. These vectors are trainable. After training (on enough data), words with similar meanings often have similar vectors.\n",
        "\n",
        "  This index-lookup is much more efficient than the equivalent operation of passing a one-hot encoded vector through a `tf.keras.layers.Dense` layer.\n",
        "\n",
        "4. A recurrent neural network (RNN) processes sequence input by iterating through the elements. RNNs pass the outputs from one timestep to their input on the next timestep.\n",
        "\n",
        "  The `tf.keras.layers.Bidirectional` wrapper can also be used with an RNN layer. This propagates the input forward and backwards through the RNN layer and then concatenates the final output.\n",
        "\n",
        "  * The main advantage of a bidirectional RNN is that the signal from the beginning of the input doesn't need to be processed all the way through every timestep to affect the output.  \n",
        "\n",
        "  * The main disadvantage of a bidirectional RNN is that you can't efficiently stream predictions as words are being added to the end.\n",
        "\n",
        "5. After the RNN has converted the sequence to a single vector the two `layers.Dense` do some final processing, and convert from this vector representation to a single logit as the classification output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4fodCI7soQi"
      },
      "source": [
        "The code to implement this is below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LwfoBkmRYcP3"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIGmIGkkouUb"
      },
      "source": [
        "Please note that Keras sequential model is used here since all the layers in the model only have single input and produce single output. In case you want to use stateful RNN layer, you might want to build your model with Keras functional API or model subclassing so that you can retrieve and reuse the RNN layer states. Please check [Keras RNN guide](https://www.tensorflow.org/guide/keras/rnn#rnn_state_reuse) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF-PsCk1LwjY"
      },
      "source": [
        "The embedding layer [uses masking](https://www.tensorflow.org/guide/keras/masking_and_padding) to handle the varying sequence-lengths. All the layers after the `Embedding` support masking:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87a8-CwfKebw",
        "outputId": "123580fe-7c77-4ae0-ace0-3ad5ccf594d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False, True, True, True, True]\n"
          ]
        }
      ],
      "source": [
        "print([layer.supports_masking for layer in model.layers])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlS0iaUIWLpI"
      },
      "source": [
        "To confirm that this works as expected, evaluate a sentence twice. First, alone so there's no padding to mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "O41gw3KfWHus",
        "outputId": "286c89f4-1de5-4e0b-f022-677b79565050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 758ms/step\n",
            "[-0.0116354]\n"
          ]
        }
      ],
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0VQmGnEWcuz"
      },
      "source": [
        "Now, evaluate it again in a batch with a longer sentence. The result should be identical:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UIgpuTeFNDzq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "[-0.0116354]\n"
          ]
        }
      ],
      "source": [
        "# predict on a sample text with padding\n",
        "\n",
        "padding = \"the \" * 2000\n",
        "predictions = model.predict(np.array([sample_text, padding]))\n",
        "print(predictions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRI776ZcH3Tf"
      },
      "source": [
        "Compile the Keras model to configure the training process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kj2xei41YZjC"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIwH3nto596k"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hw86wWS4YgR2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-15 20:33:20.085982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
            "\t [[{{node Placeholder/_1}}]]\n",
            "2024-12-15 20:33:20.086445: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
            "\t [[{{node Placeholder/_3}}]]\n",
            "2024-12-15 20:33:21.020457: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
            "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
            "2024-12-15 20:33:21.961655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
            "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.5936WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x74a6082cf8b0> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x74a6082cf8b0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-15 20:34:34.418686: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2024-12-15 20:34:34.418870: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
            "\t [[{{node Placeholder/_2}}]]\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x74a6082cf8b0> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x74a6082cf8b0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x74a6082cf8b0> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x74a6082cf8b0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "391/391 [==============================] - 77s 191ms/step - loss: 0.6313 - accuracy: 0.5936 - val_loss: 0.4860 - val_accuracy: 0.7755\n",
            "Epoch 2/10\n",
            "  1/391 [..............................] - ETA: 1:10 - loss: 0.3838 - accuracy: 0.8594"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-15 20:34:37.114595: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "345/391 [=========================>....] - ETA: 26s - loss: 0.4107 - accuracy: 0.8088"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/Neues_Projekt/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/Neues_Projekt/.venv/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n",
            "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/Neues_Projekt/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/Neues_Projekt/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    892\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    893\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_function_spec  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 894\u001b[0m       \u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    895\u001b[0m           args, kwds))\n\u001b[1;32m    896\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[1;32m    897\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39m_call_flat(   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    898\u001b[0m       filtered_flat_args,\n\u001b[1;32m    899\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
            "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/Neues_Projekt/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;66;03m# We've created variables and are unable to lift the initialization graphs,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;66;03m# so we fall back to initializing with conds while running the function.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;66;03m# TODO(b/216870587) Note that this path is not currently supported for XLA.\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile:\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnimplementedError(\n\u001b[1;32m    924\u001b[0m       \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    925\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe failed to lift variable creations out of this tf.function, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 926\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mso this tf.function cannot be run on XLA. A possible workaround is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    927\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto move variable creation outside of the XLA compiled function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    928\u001b[0m canon_args, canon_kwds, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    930\u001b[0m         args, kwds))\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compiler\u001b[38;5;241m.\u001b[39mTracingCompiler(\n\u001b[1;32m    932\u001b[0m     fn_with_cond, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfn_with_cond\u001b[39m\u001b[38;5;124m\"\u001b[39m)(canon_args, canon_kwds,\n\u001b[1;32m    933\u001b[0m                                   filtered_flat_args)\n",
            "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/Neues_Projekt/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_descriptor_cache \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mWeakKeyDictionary()\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;241m=\u001b[39m jit_compile\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/Neues_Projekt/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1752\u001b[0m     arg_names\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m   1753\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<arg\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1754\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(arg_names), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_positional_args))\n\u001b[1;32m   1755\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arg_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpretty_printed_signature\u001b[39m(\u001b[38;5;28mself\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a string summarizing the signature of this concrete function.\"\"\"\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m verbose:\n",
            "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/Neues_Projekt/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_TapeGradientFunctions\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    379\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Caches forward and backward functions compatible with eager gradients.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;124;03m  In contrast to the delayed-rewrite approach in\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m  `_DelayedRewriteGradientFunctions` which only works with delayed execution,\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m  the forward function generated by this class has a fixed set of outputs which\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m  may be preserved by a tape in order to compute gradients later.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m  This class is abstract; its child classes differ in how many side outputs of\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m  the forward function their backward function accepts gradients for, which\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m  determines whether higher-order tape gradients are possible.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    391\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func_graph, attrs, func_graph_deleter,\n\u001b[1;32m    392\u001b[0m                forwardprop_input_indices, delayed_rewrite_functions,\n\u001b[1;32m    393\u001b[0m                need_gradients_for_jvps):\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph \u001b[38;5;241m=\u001b[39m func_graph\n",
            "File \u001b[0;32m~/Development/Commercial-Brand-Differentiating-Message-Analysis/Neues_Projekt/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m     53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(train_dataset, epochs=10,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaNbXi43YgUT"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZmwt_mzaQJk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.ylim(None, 1)\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history, 'loss')\n",
        "plt.ylim(0, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwSE_386uhxD"
      },
      "source": [
        "Run a prediction on a new sentence:\n",
        "\n",
        "If the prediction is >= 0.0, it is positive else it is negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXgfQSgRW6zU"
      },
      "outputs": [],
      "source": [
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g1evcaRpTKm"
      },
      "source": [
        "## Stack two or more LSTM layers\n",
        "\n",
        "Keras recurrent layers have two available modes that are controlled by the `return_sequences` constructor argument:\n",
        "\n",
        "* If `False` it returns only the last output for each input sequence (a 2D tensor of shape (batch_size, output_features)). This is the default, used in the previous model.\n",
        "\n",
        "* If `True` the full sequences of successive outputs for each timestep is returned (a 3D tensor of shape `(batch_size, timesteps, output_features)`).\n",
        "\n",
        "Here is what the flow of information looks like with `return_sequences=True`:\n",
        "\n",
        "![layered_bidirectional](https://github.com/tensorflow/text/blob/master/docs/tutorials/images/layered_bidirectional.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbSClCrG1z8l"
      },
      "source": [
        "The interesting thing about using an `RNN` with `return_sequences=True` is that the output still has 3-axes, like the input, so it can be passed to another RNN layer, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo1jjO3vn0jo"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEPV5jVGp-is"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeSE-YjdqAeN"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, epochs=10,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LdwilM1qPM3"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykUKnAoqbycW"
      },
      "outputs": [],
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ('The movie was not good. The animation and the graphics '\n",
        "               'were terrible. I would not recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YYub0EDtwCu"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history, 'loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xvpE3BaGw_V"
      },
      "source": [
        "Check out other existing recurrent layers such as [GRU layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU).\n",
        "\n",
        "If you're interested in building custom RNNs, see the [Keras RNN Guide](https://www.tensorflow.org/guide/keras/rnn).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "text_classification_rnn.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
